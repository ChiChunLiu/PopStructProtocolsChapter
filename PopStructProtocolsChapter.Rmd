---
title: "Exploring population structure with admixture models and principal components analysis"
author: "Chi-Chun Liu, Suyash Shringapure, Ken Lange, John Novembre"
date:
output:
  html_document:
    fig_caption: yes
  pdf_document:
    fig_caption: yes
csl: springer-basic-author-date.csl.txt
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='plot/',
                      echo=TRUE, eval=FALSE, warning=TRUE, message=TRUE)
```



Population structure is a commonplace feature of genetic variation data, and it has importance in numerous application areas, including evolutionary genetics, conservation genetics, and human genetics.  At a broad level, population structure is the existence of differing levels of genetic relatedness among some subgroups within a sample.  This may arise because samples have been drawn from differentiated sub-populations or different locales across a geographic continuum. It also can arise due to the existence of close relatives in a dataset, in which case it is more precisely called family structure.  Regardless, understanding the structure in a sample is necessary before more sophisticated analyses are undertaken. For example, to infer divergence times between two populations requires knowing two populations even exist and which individuals belong to each.  

Two of the most commonly used approaches to describe population structure in a sample are principal components analysis [@Menozzi78, @CavSforza94, @Price06, @Patterson06] and the admixture proportion inference [@Pritchard00,@Novembre16a].  In brief, principal components analysis reduces a  multi-dimensional dataset to a much smaller number of dimensions that allows for visual exploration and compact quantitive summaries.  In its application to genetic data, the numerous genotypes observed per individual are reduced to a few summary coordinates. With admixture proportion infernece, individuals in a sample are modeled as having a proportion of their genome derived from each of several source populations. The goal is to infer the proportions of ancestry in each source populations, and these proportions can be used to produce compact visual summaries that reveal the existence of population structure in a sample.  

The history and basic behaviors of both these approaches have been written about extentsively, including by some of us, and so we refer readers to several previous publications to learn the basic background and interpretative nuances of these approaches and their derivatives [@Pritchard00, @Falush03, @Rosenberg05, @Hubisz09, @Raj14, @Novembre14, @Falush16, @Alexander09, @Alexander11, @Price06, @Patterson06, @Novembre08a, @McVean09, @Novembre16b]. Here, in the spirit of this volume, we provide a protocol for running these analyses and share some pragmatic caveats that do not always arise in more abstract discussions regarding these methods.  

## Materials 
The protocol we present is based on two pieces of software: 1)  the `ADMIXTURE` software that our team developed [@Alexander09] for efficiently estimating admixture proportions in the PSD model.  2) The `smartpca` software developed by Nick Patterson and colleagues for carrying out PCA [@Price06] (?).  Both of these pieces of software are used widely.  We also pair them with downstream tools for visualization, in particular `pong` [@Behr16], for visualizing output of admixture proportion inferences, and `PCAviz` [@Novembre17], a novel R package for plotting PCA outputs.  We also use `PLINK` [@Purcell07, @Chang15] as a tool to perform some basic manipulations of the data (See Chapter X for more details). 

The example data we use is derived from publicly available single-nucleotide polymorphism (SNP) genotype data from the CEPH-Human Genome Diversity Panel [@Cann02].  Specifically, we will look at Illumina 650Y genotyping array data as first described by Li et al [@Li08].  This sample is a global-scale sampling of human diversity with 52 populations in total, and the raw files are available from the
following link:
<http://hagsc.org/hgdp/files.html>.  These data have been used in numerous subsequent publications and are an important reference set.  

A few technical details are that the genotypes were filtered with a cutoff of 0.25 for the Illumina GenCall score [@GenCall] (a quality score generated by the basic genotype calling software).  Further, individuals with a genotype call rate <98.5% were removed, with the logic being that if a sample has many missing genotypes it may due to poor quality of the source DNA, and so none of the genotypes from that individual should be trusted.  Beyond this, to prepare the data, we have filtered down the individuals to a set of 938 unrelated individuals.  (The starting data are available as plink-formatted files `H938.bed` 
`H938.fam`, `H938.bim`, and an accompanying set of population identifiers `H938.clst.txt`, from this link: <https://www.dropbox.com/sh/66p1hhbtx0rb3wt/AAA0aDXVTNhjUi5nH03__D4za?dl=0>).   

As a pragmatic side note, it is common (and recommended) when carrying out analyses of population structure to merge one's data with other datasets that contain populations which may be representative sources of admixing individuals. For example, in analyzing a dataset with African American individuals, it can be helpful to include datasets containing African and European individuals in the analysis. These datasets can be merged with your dataset using software such as `plink`. However, when merging several datasets, one should be aware of potential biases that can be introduced due to strand flips (i.e. one dataset reports genotypes on the '+' strand of the reference human genome, and another on the '-' strand). One precautionary step to detect strand flips is to group individuals by what dataset they derive from and then produce a scatterplot of allele frequencies for pairs of groups at a time.  If strand flips are not being controlled correctly, one will observe numerous variants on the $y=1-x$ line, where $x$ is the frequency in one dataset and $y$ is the frequency in a second dataset.  (Note: this rule of thumb assumes levels of differentiation are low between datasets, as is the case in human datasets in general, but one should still keep this in mind interpreting results). 

## Methods

In this section we walk you through an example analysis using `ADMIXTURE` and `smartpca`.  We assume the raw data files are in a directory `raw_input` that is below our working directory and that second directory `out` exists in which outputs can be placed. If following along in an `R` console, you should use the `setwd()` command to set the working directory correctly.  

### Subsetting Data
For running some simple examples below, we will first create a subset of the HGDP sample that is restricted to only European populations. The European populations in the HGDP have the labels 'Adygei', 'Basque', 'French', 'Italian', 'Orcadian', 'Russian', 'Sardinian' and 'Tuscan', so we create a list of individuals matching these labels using an `awk` command, and then use `plink`'s `--keep` option to make a new dataset with output prefix 'H938\_Euro'. 

```{r, engine = 'bash', eval = FALSE}
awk '$3=="Adygei"||$3=="French_Basque"||$3=="French"|| \
$3=="North_Italian"||$3=="Orcadian"||$3=="Russian"|| \ 
$3=="Sardinian"||$3=="Tuscan" {print $0}' raw_input/H938.clst.txt > out/Euro.clst.txt

plink --bfile raw_input/H938 --keep out/Euro.clst.txt --make-bed --out out/H938_Euro
```

### Filter out SNPs to remove linkage disequilibrium (LD).  
SNPs in high LD with each other contain redundant information.  More worrisome is the potential for some regions of the genome to have a disproportionate influence on the results and thus distort the representation of genome-wide structure.  A nice empirical example of the problem is in Figure 5 of Tian et al [@TianetalSeldin], where PC2 of the genome-wide data is shown to be reflecting the variation in a 3.8Mb region of chromosome 8 that is known to harbor an inversion. A standard approach to address this issue is to filter out SNPs based on pairwise LD to produce a reduced set of more independent markers.  Here we use `plink`'s commands to produce a new LD-pruned dataset with output prefix `H938_Euro.LDpruned`.  The approach considers a chromosomal window of 50 SNPs at a time, and for any pair whose genotypes have an association $r^2$ value greater than 0.1, it removes a SNP from the pair.  Then the window is shifted by 10 SNPs and the procedure is repeated:  

```{r, engine = 'bash', eval = FALSE}
plink --bfile out/H938_Euro --indep-pairwise 50 10 0.1
plink --bfile out/H938_Euro --extract plink.prune.in --make-bed --out out/H938_Euro.LDprune
```

[Advanced note: For particularly sensitive results, we recommend additional rounds of SNP filtering based on observed principal component loadings and/or population differentiation statistics. For example, a robust approach is to filter out large windows aroudn any SNP with a high PCA loading, see @Novembreetal2008].
    
### Running `ADMIXTURE`
The `ADMIXTURE` software (v 1.3.0 here) comes as a pre-compiled binary executable file for either Linux or Mac operating systems. To install, simply download the package and move the executable into your standard execution path (e.g. '/usr/local/bin' on many linux systems).  Once installed, it is straightforward to run `ADMIXTURE` with a fixed number of source populations, commonly denoted by $K$. For example, to get started let's run ADMIXTURE with $K$=8 as there are 8 distinctly labelled populations in the dataset:
```{r, engine = 'bash', eval = FALSE}
admixture out/H938_Euro.LDprune.bed 8
```    
`ADMIXTURE` is a maximum-likelihood based method, so as the method runs, you will see updates to the log-likelihood as it converges on a solution for the ancestry proportions and allele frequencies that maximize the likelhood function.  The algorithm will stop when the difference between successive iterations is small (the 'delta' value takes a small value).  A final output is an estimated $F_{ST}$ value [@Kent09] between each of the source populations, based on the inferred allele frequencies.  These estimates reflect how differentiated the source populations are, which is important for understanding whether the population structure observed in a sample is substantial or not (values closer to 0 reflect less population differentiation).

After running, `ADMIXTURE` produces two major output files.  The file with suffix `.P` contains an $L \times K$ table of the allele frequencies inferred for each SNP in each population.  The file with suffix `.Q` contains an $N \times K$ table of inferred individual ancestry proportions from the $K$ ancestral populations, with one row per individual. 

For our example dataset with $K$=8, this will be a file called `H938.LDpruned.8.Q`. This file can be used to generate a plot showing individual ancestry. In `R`, this can be done using the following commands:
```{r, eval = TRUE,fig.height=2.5,fig.width=7.5}
library(RColorBrewer)
tbl=read.table("out/H938_Euro.LDprune.8.Q")
par(mar=c(1,4,2,2))
barplot(t(as.matrix(tbl)), col=brewer.pal(8,"Set1"),
        ylab="Admixture Proportions",border=NA,space=0)
```
Each thin vertical line in the barplot represents one individual and each color represents one inferred ancestral population. The length of each color in a vertical bar represents the proportion of that individual's ancestry that is derived from the inferred ancestral population corresponding to that color. The above image suggests there are some genetic clusters in the data, but it's not a well organized data display. 

To improve the visualization, one can use a package dedicated to plotting ancestry proportions [@Rosenberg04, @Kopelman15, @Behr16]. Here we use a post-processing tool `pong` [@Behr16], which visualizes individual ancestry with similarity between individuals within clusters. You will most likely want to install 'pong' on a local machine as it initializes a local web server to display the results.  

To run `pong` requires setting up a few files: 1) an `ind2pop` file that maps individuals to populations; 2) a `Qfilemap` file that points `pong` towards which '.Q' files to display; These are easy to build up from the command-line based using the `Euro.clst.txt` file we built above, and an `awk` command to output tab-seperated text to a file with the `Qfilemap` suffix added to whatever file prefix we're using to organize our runs:

```{r, engine='bash',eval=FALSE}
cut -d' ' -f3 out/Euro.clst.txt > out/H938_Euro.ind2pop
FILEPREFIX=out/H938_Euro.LDPrune
K=8
awk -v K=$K -v file=$FILEPREFIX 'BEGIN{ \
printf("ExampleRun\t%d\t%s.%d.Q\n",K,file,K) 
}' > $FILEPREFIX.Qfilemap 
```
Note when building the `.Qfilemap` one needs to use tabs to seperate the columns for `pong` to read the file correctly.

Then to run `pong`, we use following command:
```{r, engine = 'bash', eval = FALSE}
pong -m out/H938_Euro.LDprune.Qfilemap -i out/H938_Euro.ind2pop
```       
and open a web browser to `http://localhost:4000/` to view the results. 


![`pong` visualization of `admixture` output \label{figure.1}](./plot/H938_Euro.LDprune.K8.png)

From this visualization we can see the admixture model fits most individuals of the Adygei, Orcadian, and Russian samples as being derived each from a single source population (represented by orange, green, and blue respectively); the Sardinian and the French Basque samples are modeled as comprising individuals from two source populations each (yellow/red for Sardinia, brown/pink for French Basque); and the French, Tuscan, and North Italian samples are generally estimated to have a majority component of ancestry from a single source population ('purple') though with notable admixture with other sources.  A first conclusions is that the population labels do not capture the complexity of the population structure.  There is apparent cryptic structure within some samples (e.g., Sardinia) and minimal differentiation between other samples (North Italian and Tuscan samples for instance).

### Considering different values of $K$
In a typical analysis, one typically wants to explore the sensitivity of the results to the choice of $K$.  One approach is to run ADMIXTURE with various plausible values of $K$ and compare the performance of results visually and using cross-validation error rates. Here is a piece of `bash` command-line code that will run `ADMIXTURE` for values of $K$ from 2 to 12, and that will build a file with a table of cross-validation error rates per value of $K$.  

```{r, engine = 'bash', eval = FALSE}
# Run for different values of K
prefix=H938_Euro.LDprune
Klow=1
Khigh=12
for ((K=$Klow;K<=$Khigh;K++)); \
do 
  admixture --cv out/$prefix.bed $K | tee log.$prefix.${K}.out; 
done
```
Then let's compile results on cross-validation error across values of K:
```{r, engine = 'bash', eval = FALSE}
prefix=H938_Euro.LDprune
Klow=1
Khigh=12
echo '# CV results' > $prefix.CV.txt
for ((K=$Klow;K<=$Khigh;K++)); do 
  awk -v K=$K '
    $1=="CV"{print K,$4}' out/log.$prefix.$K.out >> out/$prefix.CV.txt; 
done
```
and build a Qmapfile for pong:
```{r, engine='bash', eval = FALSE}
prefix=H938_Euro.LDprune
Klow=1
Khigh=12
echo '# Qfilemap' > out/$prefix.Qfilemap
for ((K=$Klow;K<=$Khigh;K++)); \
do 
  awk -v K=$K -v prefix=$prefix 'BEGIN{ \
    printf("K%d\t%d\t%s.%d.Q\n",K,K,prefix,K)
  }' >> out/$prefix.Qfilemap; 
done
```     

Now let's inspect the outputs.  First let's make a plot of the cross-validation error as a function of $K$:
```{r,eval = TRUE,fig.width=3.25,fig.height=3}
tbl = read.table("out/H938_Euro.LDprune.CV.txt")
plot(tbl$V1,tbl$V2,xlab="K",ylab="Cross-validation error",pch=16,type='l')
```

The cross-validation error suggests a single source population can model the data adequately and larger values of $K$ lead to over-fitting.  Let's now inspect the 'pong' outputs. 

```{r, engine = 'bash', eval = FALSE}
pong -m out/H938_Euro.LDprune.Qfilemap -i out/H938_Euro.ind2pop
```  
![`pong` visualization of `admixture` output for $K$=1 through $K$=12 \label{figure.2}](./plot/mainviz_2018-9-13_13h10m14s_pong.png)
Here we see how as $K$ increases through to $K=6$, the Sardinian, Basque, Adygei, and Russian samples are modeled as descended from unique sources, at $K=7$ and $K=8$ structure within the Sardinian and Basque samples is revealed, though the Basque sub-structure is not stable at higher values of $K$.  The values of $K=9$ and above make increasingly finer scale divisions that are difficult to interpret.  

Overall, it's worth noting that the visual inspection of the results suggests several "real" clusters in the data, though in this case the cross-validation supports a value of $K=1$.  This highlights a long-standing known issue with admixutre modeling: the selection of $K$ is a difficult problem to automate in a way that is robust.  

### Some advanced options

Running `ADMIXTURE` with the `-B` option provides estimates of standard errors on the ancestry proportion inferences. The `-l` flag runs `ADMIXTURE` with a penalized likelihood that favors more sparse solutions (i.e., ancestry proportions that are closer to zero).  This is useful in settings where small, possibly erroneous ancestry proportions may be overinterpreted. By using the `-P` option, the population allele frequencies inferred from one dataset can be provided as input for inference of admixture proportions in a second dataset. This is useful individuals of unknown ancestry are being analyzed against the background of a reference sample set.  Please see the `ADMIXTURE` manual for a complete listing of options and more detail, and we encourage testing these options in test datasaets such as the one provided here. 
    
### PCA with SMARTPCA
Comparing ADMIXTURE and PCA results often helps give insight and confirmation regarding population structure in a  sample. To run PCA, a standard package that is well-suited for SNP data is the `smartpca` package maintained by Nick Patterson and Alkes Price (at http://data.broadinstitute.org/alkesgroup/EIGENSOFT/). To run it, we first set-up a basic `smartpca` parameter file from the command-line of a `bash` shell:

```{r, engine = 'bash', eval = FALSE}
PREFIX=H938_Euro.LDprune
echo genotypename: out/$PREFIX.bed > out/$PREFIX.par
echo snpname: out/H938_Euro.LDprune.bim >> out/$PREFIX.par
echo indivname: out/H938_Euro.LDprune.PCA.fam >> out/$PREFIX.par
echo snpweightoutname: out/H938_Euro.LDprune.snpeigs >> out/$PREFIX.par
echo evecoutname: out/H938_Euro.LDprune.eigs >> out/$PREFIX.par
echo evaloutname: out/H938_Euro.LDprune.eval >> out/$PREFIX.par
echo phylipoutname: out/H938_Euro.LDprune.fst >> out/$PREFIX.par
echo numoutevec: 20 >> out/$PREFIX.par
echo numoutlieriter: 0 >> out/$PREFIX.par
echo outlieroutname: out/H938_Euro.LDprune.out >> out/$PREFIX.par
echo altnormstyle: NO >> out/$PREFIX.par
echo missingmode: NO >> out/$PREFIX.par
echo nsnpldregress: 0 >> out/$PREFIX.par
echo noxdata: YES >> out/$PREFIX.par
echo nomalexhet: YES >> out/$PREFIX.par
```   
This input parameter file runs `smartpca` in its most basic mode (i.e. no automatic outlier removal or adjustments for LD - features which you might want to explore later). 

As a minor issue, `smartpca` ignores individuals in the `.fam` file if they are marked as missing in the phenotypes column. This `awk` command provides a new `.fam` file that will automatically include all individuals.
    
```{r, engine = 'bash', eval = FALSE}
awk '{print $1,$2,$3,$4,$5,1}' out/H938_Euro.LDprune.fam > out/H938_Euro.LDprune.PCA.fam
```
Now run `smartpca` with the following command. 
    
```{r, engine = 'bash', eval = FALSE}
smartpca -p ./out/H938_Euro.LDprune.par
```   
You will find the output files in the `out` sub-directory as specified in the parameter file.

#### Plotting PCA results with PCAviz
The PCAviz package can be found at https://github.com/NovembreLab/PCAviz. It provides a simple interface for quickly creating plots from PCA results. It encodes several of our favored best practices for plotting PCA (such as using abberviations for point characters and plotting median positions of each labelled group).  To install the package use:
```{r, eval=FALSE,echo=FALSE}
install.packages("devtools")
devtools::install_github("NovembreLab/PCAviz",build_vignettes = TRUE)
```

The following command in `R` generates plots showing each individual sample's position in the PCA space and the median position of each labelled group in PCA space:

```{r, eval = TRUE,echo=FALSE, results='hide',warning=FALSE,message=FALSE, fig.height=10,fig.width=10}
library(PCAviz)
library(cowplot)
prefix="out/H938_Euro.LDprune"
nPCs = 20

# Read in individual coordinates on PCs and eignvalues
PCA=read.table(paste(prefix,".eigs",sep=""))
names(PCA)=c("ID",paste("PC",(1:nPCs),sep=""),"case.control")
PCA=PCA[,1:(nPCs+1)] # Remove case/control column
eig.val = sqrt(unlist(read.table(paste(prefix,".eval",sep="")))[1:nPCs])
sum.eig= sum(unlist(read.table(paste(prefix,".eval",sep=""))))

# Read in snp weightings matrix
snpeigs = read.table(paste(prefix,".snpeigs",sep=""))
names(snpeigs)=c("ID","chr","pos",paste("PC",(1:nPCs),sep=""))
snpeigs$chr = factor(snpeigs$chr)
rownames(snpeigs) <- snpeigs$ID; snpeigs = snpeigs[,-1]

# Note smartpca pushes the plink family and individual ids together so we need to extract out the ids afresh
tmp=unlist(sapply(as.character(PCA$ID),strsplit,":"))
ids=tmp[seq(2,length(tmp),by=2)]
PCA$ID=ids

# Read in the group/cluster labels 
clst=read.table("out/Euro.clst.txt")
clst_unord=clst$V3[match(ids,clst$V2)]  # Order them to match the ids of PCA object
PCA = as.data.frame(PCA)
PCA = cbind(PCA,clst_unord)
names(PCA)[ncol(PCA)] <- "sample"

# Build the PCAviz object
hgdp <- pcaviz(dat = PCA, sdev=eig.val, var= sum.eig, rotation = snpeigs)
hgdp <- pcaviz_abbreviate_var(hgdp,"sample")

# Make PCA plots
geom.point.summary.params = list(shape = 16,stroke = 1,size = 5,
                                 alpha = .7,show.legend = F)
plot1 <- plot(hgdp,coords = paste0("PC",c(1,2)), color = "sample",
              geom.point.summary.params = geom.point.summary.params ,scale.pc.axes = 0.6)
plot2 <- plot(hgdp,coords = paste0("PC",c(2,3)), color = "sample",
              geom.point.summary.params = geom.point.summary.params ,scale.pc.axes = 0.6)
plot3 <- plot(hgdp,coords = paste0("PC",c(4,5)), color = "sample",
              geom.point.summary.params = geom.point.summary.params ,scale.pc.axes = 0.6)
plot4 <- plot(hgdp,coords = paste0("PC",c(5,6)), color = "sample",
              geom.point.summary.params = geom.point.summary.params ,scale.pc.axes = 0.6)
plot_grid(plot1,plot2,plot3,plot4)
```

First one may notice several populations are separated with PC1 and PC2, with the more isolated populations being those that were most distinguished from the others by `ADMIXTURE`. PC4 distinguishes a subset of Orcadian individuals and PC5 distinguishes two Adygei indiviuals.  PC6 corresponds to the cryptic structure observed within Sardinians in the `ADMIXTURE` analysis. 

As an alternative visualization it can be helpful to see the distribution of PC coordinates per population for each labelled group in the data:
```{r, eval = TRUE,fig.height=15,fig.width=10}
pcaviz_violin(hgdp,pc.dims =paste0("PC", c(1:10)),plot.grid.params = list(nrow = 5))
```

As mentioned above in the section on LD, it is useful to inspect the PC loadings to ensure that they broadly represent variation across the genome, rather than one or a small number of genomic regions [@Duforet-Frebourg16].  NPs that are selected in the same direction as genome-wide structure can show high loadings, but what is particularly pathological is if the only SNPs that show high loadings are all concentrated in a single region of the genome, as might occur if the PCA is explaining genomic structure (such as an inversion) rather than population structure.

```{r, eval = TRUE,fig.height=30,fig.width=8}
for (i in 1:10){
  plotname<-paste("plot",i,sep="")
  plot <- pcaviz_loadingsplot(hgdp,pc.dim=paste0("PC",i), 
                              min.rank=0.8,gap=200,color = 'chr') +
          xlab("SNPs") + ylab(paste0("PC",i," loading"))
  assign(plotname,plot)
}

plot_grid(plot1,plot2,plot3,plot4,plot5,plot6,plot7,plot8,plot9,plot10, nrow=10, align="v")

```

The proportion of total variance explained by each PC is a useful metric for understanding structure ina a sample and for evaluating how many PCs one might want to include in downstream analyses. This can be computed as  $\lambda_i / \sum_{k} \lambda_k$, with $\lambda_i$ being eigenvalues in decreasing order, and is plotted below:
```{r, eval = TRUE,warnings=FALSE,fig.width=3.25,fig.height=3}
screeplot(hgdp,type='pve')  +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      theme(axis.line = element_line(size = 1, linetype = "solid"))
```

The results show that the top PCs only explain a small fraction of the variance (<1.5%) and that after about $K=6$ the variance explained per PC becomes relatively constant; rouhgly in line with the visual inspection of the `admixture` results that revealed $K=6$ may be reasonable for this dataset. 


##  Discussion

Our protocol above is relatively straightfoward and presents the most basic implementation of these analyses. Each analysis sofware (`ADMIXTURE` and `smartpca`) and each visualization package (`pong` and `PCAviz`) contain numerous other options that may be suitable for specific analyses and we encourage the readers to spend time in the manuals of each.  Nonetheless, what we have presented is a useful start and a standard pipeline that we use in our research.

Two broad perspecives we find helpful useful to keep in mind are: 1) How the admixture model and PCA framework are related to each other indirectly as different forms of sparse factor analyss [@Engelhardt10]; 2) How the PCA framework in particular can be considered as a form of efficient data compression.  Both of these perspectives can be helpful in interpreting the outputs of the methods and for appreciating how these approaches best serve as helpful visual exploratory tools for analyzing structure in genetic data.  These methods are ultimately relatively simple statistical tools being used to summarize complex realites.  They are part of the toolkit for analysis, and often are extremely useful for framing specific models of population structure that can be further investigated using more detailed and explicit approachs (such as those based on coalescent or diffusion theory, Chapters XX and XX). 


## References
